{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ea7196",
   "metadata": {},
   "source": [
    "## Visualisation of Backpropagadion on 3 Neural networks\n",
    "- Raw\n",
    "- L1 normalized\n",
    "- L2 normalized\n",
    "\n",
    "networks will try to classify (x,y) ∈ (-1, 1)² if their product >= 0 or <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42552da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Layers import DenseLayer\n",
    "from Activation import *\n",
    "from trainutils import *\n",
    "from Loss import Crossentropy\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef9e3e7",
   "metadata": {},
   "source": [
    "Let's prepare parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0390da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'lr': 0.1,                  # Learning rate\n",
    "    'batch_size': 128,          # Batch size\n",
    "    'epochs': 500,              # Number of epochs\n",
    "    'lr_decay': 0.9999,         # Learning rate decay factor to not overfit\n",
    "    'momentum': 0.9,            # Momentum factor\n",
    "}\n",
    "BATCH_SIZE = hparams['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc38d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_random_data(10000, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "y_test = matrix_encode(y_test)\n",
    "y_train = matrix_encode(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d4329a",
   "metadata": {},
   "source": [
    "Make a network model by stacking layers (Choose 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bcc841",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\n",
    "    DenseLayer(input_size=X_train.shape[0], output_size=4),\n",
    "    Relu(),\n",
    "    Dense_Softmax_Cross_Entropy(input_size=4, output_size=2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae83d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\n",
    "    DenseLayer(input_size=X_train.shape[0], output_size=4),\n",
    "    Sigmoid(),\n",
    "    Dense_Softmax_Cross_Entropy(input_size=4, output_size=2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b02237",
   "metadata": {},
   "source": [
    "Propagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b55a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(hparams['epochs']):\n",
    "    epoch_cost = 0\n",
    "    epoch_acc = 0\n",
    "    for batch_num in range(int(math.ceil(X_train.shape[1] / BATCH_SIZE))):\n",
    "        input = X_train[:, batch_num * BATCH_SIZE:(batch_num + 1) * BATCH_SIZE]\n",
    "        y_batch = y_train[:, batch_num * BATCH_SIZE:(batch_num + 1) * BATCH_SIZE]\n",
    "\n",
    "        # Forward pass\n",
    "        for layer in model:\n",
    "            input = layer.forward(input)\n",
    "\n",
    "        acc = get_accuracy(y_batch, input)\n",
    "        cost = Crossentropy(y_batch, input)\n",
    "\n",
    "        epoch_cost += cost\n",
    "        epoch_acc += acc\n",
    "\n",
    "        gradient = y_batch\n",
    "        \n",
    "        # Backward pass\n",
    "        for layer in reversed(model):\n",
    "            gradient = layer.backward(gradient, hparams)\n",
    "\n",
    "    epoch_acc /= int(math.ceil(X_train.shape[1] / BATCH_SIZE))\n",
    "    hparams['lr'] *= hparams['lr_decay']\n",
    "    print(f\"Epoch: {epoch}, cost: {epoch_cost}, acc: {epoch_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a7280",
   "metadata": {},
   "source": [
    "Weights peek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model:\n",
    "    if isinstance(layer, DenseLayer):\n",
    "        print(f\"Weights:\\n{layer.weights}\\n, Bias:\\n{layer.bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35889395",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = X_test\n",
    "for layer in model:\n",
    "    input = layer.forward(input)\n",
    "acc = get_accuracy(y_test, input)\n",
    "print(f\"Test accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a84a5",
   "metadata": {},
   "source": [
    "Test for random new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X, input_labels = generate_random_data(10000, random_state=123) # Different random state\n",
    "input = input_X\n",
    "\n",
    "for layer in model:\n",
    "    input = layer.forward(input)\n",
    "\n",
    "input_labels_oh = matrix_encode(input_labels.flatten())\n",
    "\n",
    "acc = get_accuracy(input_labels_oh, input)\n",
    "print(f\"Test accuracy on new data: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20933f60",
   "metadata": {},
   "source": [
    "### Now for L1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b034",
   "metadata": {},
   "source": [
    "Let's prepare parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'lr': 0.1,                  # Learning rate\n",
    "    'batch_size': 128,          # Batch size\n",
    "    'epochs': 500,              # Number of epochs\n",
    "    'lr_decay': 0.9999,         # Learning rate decay factor to not overfit\n",
    "    'momentum': 0.9,            # Momentum factor\n",
    "}\n",
    "BATCH_SIZE = hparams['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc07517",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_random_data(10000, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "y_test = matrix_encode(y_test)\n",
    "y_train = matrix_encode(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a04fa6",
   "metadata": {},
   "source": [
    "Make a network model by stacking layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026761f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\n",
    "    L1(),\n",
    "    DenseLayer(input_size=X_train.shape[0], output_size=4),\n",
    "    Relu(),\n",
    "    Dense_Softmax_Cross_Entropy(input_size=4, output_size=2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\n",
    "    L1(),\n",
    "    DenseLayer(input_size=X_train.shape[0], output_size=4),\n",
    "    Sigmoid(),\n",
    "    Dense_Softmax_Cross_Entropy(input_size=4, output_size=2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0416e",
   "metadata": {},
   "source": [
    "Propagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(hparams['epochs']):\n",
    "    epoch_cost = 0\n",
    "    epoch_acc = 0\n",
    "    for batch_num in range(int(math.ceil(X_train.shape[1] / BATCH_SIZE))):\n",
    "        input = X_train[:, batch_num * BATCH_SIZE:(batch_num + 1) * BATCH_SIZE]\n",
    "        y_batch = y_train[:, batch_num * BATCH_SIZE:(batch_num + 1) * BATCH_SIZE]\n",
    "\n",
    "        # Forward pass\n",
    "        for layer in model:\n",
    "            input = layer.forward(input)\n",
    "\n",
    "        acc = get_accuracy(y_batch, input)\n",
    "        cost = Crossentropy(y_batch, input)\n",
    "\n",
    "        epoch_cost += cost\n",
    "        epoch_acc += acc\n",
    "\n",
    "        gradient = y_batch\n",
    "        \n",
    "        # Backward pass\n",
    "        for layer in reversed(model):\n",
    "            gradient = layer.backward(gradient, hparams)\n",
    "\n",
    "    epoch_acc /= int(math.ceil(X_train.shape[1] / BATCH_SIZE))\n",
    "    hparams['lr'] *= hparams['lr_decay']\n",
    "    print(f\"Epoch: {epoch}, cost: {epoch_cost}, acc: {epoch_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd1813",
   "metadata": {},
   "source": [
    "Weights peek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model:\n",
    "    if isinstance(layer, DenseLayer):\n",
    "        print(f\"Weights:\\n{layer.weights}\\n, Bias:\\n{layer.bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617f3102",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550430ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = X_test\n",
    "for layer in model:\n",
    "    input = layer.forward(input)\n",
    "acc = get_accuracy(y_test, input)\n",
    "print(f\"Test accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ba447",
   "metadata": {},
   "source": [
    "Test for random new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X, input_labels = generate_random_data(10000, random_state=123) # Different random state\n",
    "input = input_X\n",
    "\n",
    "for layer in model:\n",
    "    input = layer.forward(input)\n",
    "\n",
    "input_labels_oh = matrix_encode(input_labels.flatten())\n",
    "\n",
    "acc = get_accuracy(input_labels_oh, input)\n",
    "print(f\"Test accuracy on new data: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d0839",
   "metadata": {},
   "source": [
    "### Now for L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a2799",
   "metadata": {},
   "source": [
    "Let's prepare parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef67f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'lr': 0.1,                  # Learning rate\n",
    "    'batch_size': 128,          # Batch size\n",
    "    'epochs': 500,              # Number of epochs\n",
    "    'lr_decay': 0.9999,         # Learning rate decay factor to not overfit\n",
    "    'momentum': 0.9,            # Momentum factor\n",
    "}\n",
    "BATCH_SIZE = hparams['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_random_data(10000, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "y_test = matrix_encode(y_test)\n",
    "y_train = matrix_encode(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aef1c7",
   "metadata": {},
   "source": [
    "Make a network model by stacking layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08336846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\n",
    "    L2(),\n",
    "    DenseLayer(input_size=X_train.shape[0], output_size=4),\n",
    "    Relu(),\n",
    "    Dense_Softmax_Cross_Entropy(input_size=4, output_size=2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a179b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [\n",
    "    L2(),\n",
    "    DenseLayer(input_size=X_train.shape[0], output_size=4),\n",
    "    Sigmoid(),\n",
    "    Dense_Softmax_Cross_Entropy(input_size=4, output_size=2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc962d",
   "metadata": {},
   "source": [
    "Propagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da65f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(hparams['epochs']):\n",
    "    epoch_cost = 0\n",
    "    epoch_acc = 0\n",
    "    for batch_num in range(int(math.ceil(X_train.shape[1] / BATCH_SIZE))):\n",
    "        input = X_train[:, batch_num * BATCH_SIZE:(batch_num + 1) * BATCH_SIZE]\n",
    "        y_batch = y_train[:, batch_num * BATCH_SIZE:(batch_num + 1) * BATCH_SIZE]\n",
    "\n",
    "        # Forward pass\n",
    "        for layer in model:\n",
    "            input = layer.forward(input)\n",
    "\n",
    "        acc = get_accuracy(y_batch, input)\n",
    "        cost = Crossentropy(y_batch, input)\n",
    "\n",
    "        epoch_cost += cost\n",
    "        epoch_acc += acc\n",
    "\n",
    "        gradient = y_batch\n",
    "        \n",
    "        # Backward pass\n",
    "        for layer in reversed(model):\n",
    "            gradient = layer.backward(gradient, hparams)\n",
    "\n",
    "    epoch_acc /= int(math.ceil(X_train.shape[1] / BATCH_SIZE))\n",
    "    hparams['lr'] *= hparams['lr_decay']\n",
    "    print(f\"Epoch: {epoch}, cost: {epoch_cost}, acc: {epoch_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15bc98",
   "metadata": {},
   "source": [
    "Weights peek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3585330",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model:\n",
    "    if isinstance(layer, DenseLayer):\n",
    "        print(f\"Weights:\\n{layer.weights}\\n, Bias:\\n{layer.bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e786ac",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = X_test\n",
    "for layer in model:\n",
    "    input = layer.forward(input)\n",
    "acc = get_accuracy(y_test, input)\n",
    "print(f\"Test accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973fa12e",
   "metadata": {},
   "source": [
    "Test for random new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X, input_labels = generate_random_data(10000, random_state=123) # Different random state\n",
    "input = input_X\n",
    "\n",
    "for layer in model:\n",
    "    input = layer.forward(input)\n",
    "\n",
    "input_labels_oh = matrix_encode(input_labels.flatten())\n",
    "\n",
    "acc = get_accuracy(input_labels_oh, input)\n",
    "print(f\"Test accuracy on new data: {acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
